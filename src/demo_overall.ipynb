{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "MARIPOSA_PATH = \"/home/yizhou7/mariposa/\"\n",
    "\n",
    "sys.path.append(MARIPOSA_PATH + \"src\")\n",
    "os.chdir(MARIPOSA_PATH)\n",
    "\n",
    "from debugger.tree_node import NodeRef\n",
    "from evaluator import BenchViewer, Evaluator\n",
    "from debugger.debugger import Debugger3\n",
    "from evaluator import DebuggerStatus\n",
    "from benchmark_consts import *\n",
    "from utils.system_utils import list_smt2_files, get_name_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[91m[ERROR] no such project group singleton_f6db5998ec \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m[WARN] [eval] e695dc7eeb tested count 1159 < registered 1160 \u001b[0m\n",
      "\u001b[93m[WARN] [eval] cc5b8bed53 tested count 289 < registered 497 \u001b[0m\n",
      "\u001b[93m[WARN] [eval] 0e45874c62 tested count 991 < registered 993 \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[91m[ERROR] no such project group singleton_0b72dcef64 \u001b[0m\n",
      "\u001b[91m[ERROR] no such project group singleton_90e97b47ee \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m[WARN] [eval] d8cf640f87 tested count 1043 < registered 1044 \u001b[0m\n",
      "\u001b[93m[WARN] [eval] be808dd0c3 tested count 997 < registered 998 \u001b[0m\n",
      "\n",
      "\u001b[93m[WARN] [eval] 203627efb4 tested count 6 < registered 404 \u001b[0m\u001b[93m[WARN] [eval] 9b9e796545 tested count 1076 < registered 1079 \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[91m[ERROR] no such project group singleton_d874a82c3a \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m[WARN] [init] previous debugging attempt has failed, run with --retry-failed if needed! \u001b[0m\n",
      "\u001b[93m[WARN] [proof] no proof available \u001b[0m\n",
      "\u001b[93m[WARN] [init] previous debugging attempt has failed, run with --retry-failed if needed! \u001b[0m\n",
      "\u001b[93m[WARN] [proof] no proof available \u001b[0m\n",
      "\u001b[93m[WARN] [init] previous debugging attempt has failed, run with --retry-failed if needed! \u001b[0m\n",
      "\u001b[93m[WARN] [proof] no proof available \u001b[0m\n",
      "\u001b[93m[WARN] [init] previous debugging attempt has failed, run with --retry-failed if needed! \u001b[0m\n",
      "\n",
      "\u001b[93m[WARN] [proof] no proof available \u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[91m[ERROR] no such project group singleton_b1b86518f3 \u001b[0m\n",
      "\u001b[91m[ERROR] no such project group singleton_ee8d1ab295 \u001b[0m\n",
      "\u001b[91m[ERROR] no such project group singleton_e93855aadd \u001b[0m\n",
      "\u001b[91m[ERROR] no such project group singleton_ab52dadac1 \u001b[0m\n",
      "\u001b[91m[ERROR] no such project group singleton_563f5abfa4 \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m[WARN] [eval] 519fdc89c1 tested count 506 < registered 508 \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "qs = UNSTABLE_MARIPOSA\n",
    "mv = BenchViewer(qs)\n",
    "# vv = BenchViewer(UNSTABLE_VERUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| category                                      |   count | percentage   |\n",
      "|-----------------------------------------------|---------|--------------|\n",
      "| DebuggerStatus.FINISHED                       |     523 | 95.96 %      |\n",
      "| DebuggerStatus.SINGLETON_CREATION_UNATTEMPTED |       9 | 1.65 %       |\n",
      "| DebuggerStatus.SINGLETON_CREATION_FAILED      |       9 | 1.65 %       |\n",
      "| DebuggerStatus.NO_PROOF                       |       4 | 0.73 %       |\n",
      "| total                                         |     545 | 100.00 %     |\n"
     ]
    }
   ],
   "source": [
    "mv.status.print_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in mv.status[DebuggerStatus.SINGLETON_CREATION_UNATTEMPTED]:\n",
    "    print(\"./src/debugger3.py --create-singleton -i\", q)\n",
    "\n",
    "for q in mv.status[DebuggerStatus.SINGLETON_CREATION_FAILED]:\n",
    "    print(\"./src/debugger3.py --create-singleton -i\", q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in mv.status[DebuggerStatus.SINGLETON_NOT_RAN]:\n",
    "# for q in mv.status[DebuggerStatus.SINGLETON_TESTED_EMPTY]:\n",
    "    assert len(list_smt2_files(mv[q].singleton_dir)) != 0\n",
    "    print(\"./src/exper_wizard.py manager -e verify --total-parts 12 -i \", mv[q].singleton_dir, \"--clear\")\n",
    "    print(\"./src/analysis_wizard.py singleton -e verify -s z3_4_13_0 -i \", mv[q].singleton_dir)\n",
    "    print(\"python3 src/carve_and_rerun.py\", mv[q].filtered_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# print(len(mv.fixable)/len(mv.status[DebuggerStatus.FINISHED]))\n",
    "\n",
    "bad_min_ranks = dict()\n",
    "min_ranks = []\n",
    "\n",
    "for q in mv.fixable:\n",
    "    r = mv.reviewers[q]\n",
    "    report = r.build_report()\n",
    "    indices = report.freq.loc[report.freq[\"qname\"].isin(report.stabilized[\"qname\"])].index\n",
    "    report.freq[\"rank\"] = report.freq[\"trace_count\"].rank(method='min', ascending=False)\n",
    "    min_rank = report.freq.loc[indices][\"rank\"].min()\n",
    "    max_rank = report.freq.loc[indices][\"rank\"].max()\n",
    "    min_ranks.append(min_rank)\n",
    "    if min_rank <= 10:\n",
    "        continue\n",
    "    bad_min_ranks[q] = (min_rank, len(indices))\n",
    "\n",
    "min_ranks = np.array(min_ranks)\n",
    "\n",
    "for q, (rank, feasible) in bad_min_ranks.items():\n",
    "    print(int(rank), feasible, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_ratio(x, y):\n",
    "    return f\"({round(x / y * 100, 1)}%)\"\n",
    "\n",
    "def fmt_ratio_2(x, y):\n",
    "    return f\"{x}/{y} ({round(x / y * 100, 1)}%)\"\n",
    "\n",
    "def count_leq(r, n):\n",
    "    return np.where(r <= n)[0].shape[0]\n",
    "\n",
    "fixable_count = len(mv.fixable)\n",
    "finished_count = len(mv.status[DebuggerStatus.FINISHED])\n",
    "bench_total = mv.status.total\n",
    "print(\"finished\", fmt_ratio_2(finished_count, bench_total))\n",
    "print(\"\\tfixable\", fmt_ratio_2(fixable_count, finished_count))\n",
    "rcount = count_leq(min_ranks, 1)\n",
    "print(\"\\t\\t\", \"top-1 \", fmt_ratio_2(rcount, fixable_count))\n",
    "rcount = count_leq(min_ranks, 3)\n",
    "print(\"\\t\\t\", \"top-3 \", fmt_ratio_2(rcount, fixable_count))\n",
    "rcount = count_leq(min_ranks, 10)\n",
    "print(\"\\t\\t\", \"top-10\", fmt_ratio_2(rcount, fixable_count))\n",
    "print(\"\\tno-fixes\", fmt_ratio_2(finished_count - fixable_count, finished_count))\n",
    "no_proof = len(mv.status[DebuggerStatus.NO_PROOF])\n",
    "print(\"no-proof\", fmt_ratio_2(no_proof, bench_total))\n",
    "parse_fail = len(mv.status[DebuggerStatus.SINGLETON_CREATION_UNATTEMPTED]) + len(mv.status[DebuggerStatus.SINGLETON_CREATION_FAILED])\n",
    "print(\"parse-fail\", fmt_ratio_2(parse_fail, bench_total))\n",
    "in_progress = bench_total - finished_count - parse_fail - no_proof\n",
    "print(\"in-progress\", fmt_ratio_2(in_progress, bench_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in mv.status[DebuggerStatus.NO_PROOF]:\n",
    "    print('\"' + mv[q].name_hash + '\"', end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs_to_send = []\n",
    "additional = \"\"\n",
    "\n",
    "for q in mv.fixable:\n",
    "    r = mv.reviewers[q]\n",
    "    if r.name_hash in LIKELY_FIXED:\n",
    "        continue\n",
    "    r.collect_garbage()\n",
    "    dirs_to_send += r.get_dirs_to_sync()\n",
    "    additional += f\"\\\"{r.name_hash}\\\",\\n\"\n",
    "\n",
    "print(additional)\n",
    "\n",
    "for i, d in enumerate(dirs_to_send):\n",
    "    if i % 5 == 0:\n",
    "        print(\"echo '\", (i //5 +1), \"/\", len(dirs_to_send)//5, \"'\")\n",
    "    print(\"rsync -avz\", d, \"g2001:/home/yizhou7/mariposa/\", \"--inplace\", \"--delete\", \"--relative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.analysis_utils import Categorizer\n",
    "\n",
    "f_modes = Categorizer()\n",
    "\n",
    "for query in mv.unfixable:\n",
    "    rev: Evaluator = mv[query]\n",
    "    mi = rev.get_trace_info()\n",
    "    reason = mi.get_failed_reason()\n",
    "    f_modes.add_item(reason, query)\n",
    "\n",
    "f_modes.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| category                  |   count | percentage   |\n",
      "|---------------------------|---------|--------------|\n",
      "| TraceFailure.TIMEOUT      |     116 | 82.27 %      |\n",
      "| TraceFailure.FAST_UNKNOWN |      22 | 15.6 %       |\n",
      "| TraceFailure.SLOW_UNKNOWN |       3 | 2.13 %       |\n",
      "| total                     |     141 | 100.00 %     |\n"
     ]
    }
   ],
   "source": [
    "f_modes.print_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
